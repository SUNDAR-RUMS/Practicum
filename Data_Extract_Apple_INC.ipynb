{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHTMLContent(inputFile,outputFile):\n",
    "    try:\n",
    "\n",
    "        csv_file = open(outputFile, 'w', encoding=\"UTF-8\", newline=\"\")\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        writer.writerow(\n",
    "            ['published_date','GoldsteinScale', 'QuadClass', 'AvgTone','link_url', 'tag_name', 'link_title_string', 'commentCounter', 'comment'])\n",
    "\n",
    "        with open(inputFile, mode='r') as csv_reader_file:\n",
    "            csv_reader = csv.DictReader(csv_reader_file)\n",
    "\n",
    "            record_counter = 0\n",
    "            for row in csv_reader:\n",
    "                postedDate=row['published_date']\n",
    "                sourceURL=str(row['link_url'])\n",
    "                goldsteinScale=str(row['GoldsteinScale'])\n",
    "                quadClass=str(row['QuadClass'])\n",
    "                avgTone=str(row['AvgTone'])  \n",
    "                url_Status=str(row['URL_Status'])\n",
    "                #print(postedDate,sourceURL)\n",
    "                if (url_Status != \"Invalid URL\") :\n",
    " \n",
    "                    ##############################\n",
    "                    try:\n",
    "                        pageTitleString=\"\"\n",
    "                        htmlPage=\"\"\n",
    "                        dateStamp=postedDate\n",
    "                        htmlLink = sourceURL\n",
    "                        try:\n",
    "                            urlLink = urlopen(htmlLink)\n",
    "                            #time.sleep(3)\n",
    "                            htmlPage = urlLink.read()\n",
    "                            urlLink.close()\n",
    "                        except IOError:\n",
    "                            print (\"Error while opening \".format(htmlLink))\n",
    "                        except Exception as e:\n",
    "                            print (\"Unexcepted Invalid URL error.\".format(htmlLink))\n",
    "                            print ('Reason: ', e)\n",
    "                            #print ('Error code: ', e.code)\n",
    "\n",
    "                        htmlPagecontent=\"\"\n",
    "                        contentDetails = {}\n",
    "                        htmlPagecontent = BeautifulSoup(htmlPage)\n",
    "\n",
    "                        # title of the page\n",
    "                        # get values:\n",
    "                       # print(htmlPagecontent.title.string)\n",
    "                        pageTitleString=htmlPagecontent.title.string\n",
    "\n",
    "                        paraGraphCounter=0;\n",
    "                        paraGraphContent=\"\";\n",
    "                        for paragraph in htmlPagecontent.find_all('p'):\n",
    "                            paraGraphCounter=paraGraphCounter+1\n",
    "                            #print(\"Paragraph \" + str(paraGraphCounter))\n",
    "                            paraGraphCounterText=str(paraGraphCounter)\n",
    "                            #print(str(paragraph.text))\n",
    "                            paraGraphContent=paraGraphContent.strip()\n",
    "                            paraGraphContent=paraGraphContent+str(paragraph.text)\n",
    "                        contentDetails['published_date'] = dateStamp\n",
    "                        contentDetails['GoldsteinScale'] = goldsteinScale\n",
    "                        contentDetails['QuadClass'] = quadClass\n",
    "                        contentDetails['AvgTone'] = avgTone\n",
    "                        contentDetails['link_url'] = htmlLink\n",
    "                        contentDetails['tag_name'] = 'Paragraph'\n",
    "                        contentDetails['link_title_string'] = pageTitleString\n",
    "                        contentDetails['commentCounter'] = paraGraphCounterText\n",
    "                        contentDetails['comment'] = paraGraphContent  #commentDetails\n",
    "                        writer.writerow(contentDetails.values())\n",
    "\n",
    "                    except Exception as err:\n",
    "                        print(err)       \n",
    "\n",
    "                    ##############################\n",
    "\n",
    "                    record_counter += 1\n",
    "            print(inputFile + ' Processed  lines ' + str(record_counter) +' saved in ' + outputFile)\n",
    "            csv_file.close()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        csv_file.close()\n",
    "        # driver.close()\n",
    "    print(\"Completed\")\n",
    "\n",
    "    csv_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "results-Correct_Link_APPL_INC_1.csv DataExtract_APPL_INC_1.csv\n",
      "'NoneType' object has no attribute 'string'\n",
      "'NoneType' object has no attribute 'string'\n",
      "'NoneType' object has no attribute 'string'\n",
      "'NoneType' object has no attribute 'string'\n",
      "Unexcepted Invalid URL error.\n",
      "Reason:  HTTP/1.1 404: Not Found\n",
      "\n",
      "'NoneType' object has no attribute 'string'\n",
      "'NoneType' object has no attribute 'string'\n",
      "results-Correct_Link_APPL_INC_1.csv Processed  lines 133 saved in DataExtract_APPL_INC_1.csv\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "for fileCounter in range(1, 2, 1):\n",
    "    print(fileCounter)\n",
    "    inputFileName=\"results-Correct_Link_APPL_INC_\" + str(fileCounter) + \".csv\"\n",
    "    outputFileName=\"DataExtract_APPL_INC_\" + str(fileCounter) + \".csv\"\n",
    "    print(inputFileName,outputFileName)\n",
    "    extractHTMLContent(inputFileName,outputFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
